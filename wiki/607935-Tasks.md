## Introduction

The NLP Sandbox aims to provide a cloud-based environment that enables the
systematic and continuous benchmarking of NLP Tools that solve specific Tasks.

The first series of NLP Tasks targeted by the NLP Sandbox are the annotation and
de-identification of Protected Health Information (PHI) in clinical notes. This
first series of tasks have been identified through our collaboration with the
first NLP Sandbox Driver, the [National Center for Date to Health (CD2H)].

However, we are counting on more Drivers to collaborate with the NLP Sandbox
Team and its community to identify additional Tasks and then enable Developers
to benchmark the performance of tools that address these tasks. Examples of
additional tasks that may be added to the NLP Sandbox are the annotation of
medication intake, obesity status, and heart disease risk factor.

## Benchmarking NLP Tools

The NLP Sandbox has been designed to promote the development of Tools that have
the following properties:

- Robust and reliable
- Reproducible
- Re-usable
- Portable
- Cloud-friendly

A core element of the design of the NLP Sandbox in enabling the above properties
is the definition of common tool and data schemas. These schemas are defined
using the [OpenAPI specification] and are stored in the GitHub repository
[nlpsandbox/nlpsandbox-schemas] (see Section OpenAPI TODO). After collaborating
with an NLP Sandbox Driver to identify the specification of a new NLP Task /
Tool, we will make the new specification available to the community so that NLP
Developers can start building tools that meet the new specification.

In order to benchmark the performance of new NLP Tools, the Driver who is
proposing a new NLP Task should ideally also enable Developers to benchmark the
performance of their implementation by providing a dataset formatted according
to the proposed schemas. In the model-to-data approach implemented by the NLP
Sandbox, developers submit NLP Tools for evaluation on [nlpsandbox.io]. The
submitted tools are then automatically and concurrently pulled by NLP Sandbox
Data Hosting Sites that evaluate the performance of the tools on public or
private data. Because private datesets may include sensitive information such as
PHI, the evaluation of a tool is performed in a secure environment deployed and
controlled by the data provider (e.g. a university or hospital). The only
information returned by the Data Hosting Sites to the [nlpsandbox.io] is the
performance of the tools. This performance is then made visible to the community
in the Leaderboard defined for this NLP Task.

## Developing modular NLP Tools

Another objective of the NLP Sandbox is to promote and accelerate the
development of tools that are re-usable and interoperable. This is achieved by
decomposing complex tasks into smaller tasks that can be individually
benchmarked. As an example, the [NLP Sandbox PHI Deidentifier
Task][phi-annotation-task] proposed by CD2H has been decomposed into the
following annotation tasks (and counting):

- [Date Annotator][phi-annotation-task]
- [Person Name Annotator][phi-annotation-task]
- [Physical Address Annotator][phi-annotation-task]

Because the scope of these tasks is smaller than the entire de-identification
tasks, Developers are able to make their first submission to [nlpsandbox.io]
faster than if they were required to submit a complete PHI de-identification
tool.

Another motivation for benchmarking smaller tasks individually is to enable NLP
Developers to identify where their time and contributions can be best put to
use. For example, a Developer wants to contribute to the de-identification of
PHI in clinical notes. The Developer can use the NLP Sandbox Leaderboards to
identify that the there are already several Date Annotators that achieve near
perfect scores while no satisfying Physical Address Annotator has been submitted
yet.




 For example, a Developer who want to contribute to the de-identification of
PHI in clinical notes would use the NLP Sandbox to review and compare the
performance of previsouly submitted tools relevant to PHI de-identification.


A Developer can obtain this information with the NLP Sandbox by by reviewing and
comparing the Leaderboards of sub-tasks. If there are already several Date
Annotators with near perfect scores, then


For example, a Developer who want to contribute to the de-identification of
PHI in clinical notes would start by reviewing and comparing the Leaderboards of
sub-tasks.



to enable Developers to identify where their time and contributions can best be
put in use. For example, a Developer who is interested in contributing to the
de-identification of PHI information can start by exploring the performance of
previously submitted tools to related tasks. I



the [NLP Sandbox PHI Deidentifier Task][phi-annotation-task] that
we are developing will enable Developers to build PHI Deidentifiers that rely on
existing Tools such as:


 leverage previously benchmarked tools to accelerate the
development of new, possibly more complex tasks.



As an example, the [NLP Sandbox PHI Deidentifier Task][phi-annotation-task] that
we are developing will enable Developers to build PHI Deidentifiers that rely on
existing Tools such as:

- [Date Annotator][phi-annotation-task]
- [Person Name Annotator][phi-annotation-task]
- [Physical Address Annotator][phi-annotation-task]



<!-- Links -->

[National Center for Date to Health (CD2H)]: https://cd2h.org/
[nlpsandbox/nlpsandbox-schemas]: https://github.com/nlpsandbox/nlpsandbox-schemas
[OpenAPI specification]: https://github.com/OAI/OpenAPI-Specification
[nlpsandbox.io]: https://nlpsandbox.io
[NLP Sandbox PHI Deidentifier API]: https://nlpsandbox.github.io/nlpsandbox-schemas/phi-deidentifier/latest/docs
[phi-annotation-task]: https://www.synapse.org/#!Synapse:syn22277124/wiki/608037
